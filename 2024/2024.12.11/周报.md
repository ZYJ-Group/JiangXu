# 周报
## 本周任务
 
 -  细致研究CGAN代码，记录学习笔记，阅读跨模态相关的论文
## 下周任务

 -  继续研究CGAN代码，记录学习笔记，阅读跨模态相关的论文（两域数据集之间不一一对应的情况）
### 通道注意力机制（CAM） 空间注意力机制（SAM）

> 注意力机制：忽略不重要的特征 （减小或加大权重）

 1. 注意力机制的结构==压缩==和==激励==

 ![输入图片说明](/2024/2024.12.11/img/1.png)

 2. 输入图像经过F（卷积啥的特征提取）到HWC然后空间层面上平均池化`self.avg_pool=AdaptivePool2d(output_size(1))`压缩成`1*1*c`的向量
 ![输入图片说明](/2024/2024.12.11/img/2.png)
 
 3. ==压缩成一个向量（通道数保持不变，用以乘以对应的通道，加强或抑制某些特征）==
 4. 激励层： FC 全链接层 两个FC先降维再升维
 5.  sigmoid压缩至（0，1）形成权重，把输入的特征通道与对应的每一个权重相乘
>  SENet只考虑了通道之间的相关性而忽略了位置之间的相关性
### 通道注意力和空间注意力的串联

![输入图片说明](/2024/2024.12.11/img/3.png)

 1.通过通道注意力模块得到通道的权重 与输入通道相乘 调整通道特征
 
 2.再通过空间注意力模块得到空间的权重
 
 ***通道注意力模块***
 1. MaxPool 提取最有效的特征（丢失一些次重要的信息）
 2. AvgPool去弥补MaxPool的信息丢失
 3. MLP多层感知机（也叫全连接FC）全连接共享参数（减小参数的数量降低复杂度）
 4. 相加 sigmoid形成权重
 ![输入图片说明](/2024/2024.12.11/img/4.png)

**空间注意力模块**==压缩通道的数量==强调特征图空间位置的重要性，而更好地捕获局部信息。
![输入图片说明](/2024/2024.12.11/img/5.png)

### 现有改进版
 ![输入图片说明](/2024/2024.12.11/img/6.png)
 ```py
import torch  
import torch.nn as nn  
import math  
  
  
class CBAM(nn.Module):  
    def __init__(self,in_channel,reduction=16,kernel_size=7):  #通道压缩比reduction
        super(CBAM, self).__init__()  
        #通道注意力机制   通道数不变 改变空间尺寸为一个数（权重）
        self.max_pool=nn.AdaptiveMaxPool2d(output_size=1)      #自适应最大池化层输出1*1*C只改变空间尺寸
        self.avg_pool=nn.AdaptiveAvgPool2d(output_size=1)      #平均池化弥补信息丢失 
        self.mlp=nn.Sequential(  #nn.Sequential是有序容器 定义线性层 激活层等步骤
            nn.Linear(in_features=in_channel,out_features=in_channel//reduction,bias=False),  #线性层 调整通道（压缩）
            nn.ReLU(),  
            nn.Linear(in_features=in_channel//reduction,out_features=in_channel,bias=False)  #线性层 调整通道（恢复）
        )  
        self.sigmoid=nn.Sigmoid()  #生成通道权重
        #空间注意力机制  （空间尺寸不变）把通道数变成一个
        self.conv=nn.Conv2d(in_channels=2,out_channels=1,kernel_size=kernel_size ,stride=1,padding=kernel_size//2,bias=False)  #padding的目的是在卷积后，不改变空间尺寸
  
    def forward(self,x):  
        #通道注意力机制  
        maxout=self.max_pool(x)  
        maxout=self.mlp(maxout.view(maxout.size(0),-1))  
        avgout=self.avg_pool(x)  
        avgout=self.mlp(avgout.view(avgout.size(0),-1))  
        channel_out=self.sigmoid(maxout+avgout)  
        channel_out=channel_out.view(x.size(0),x.size(1),1,1)  
        channel_out=channel_out*x  
        #空间注意力机制  
        max_out,_=torch.max(channel_out,dim=1,keepdim=True)  
        mean_out=torch.mean(channel_out,dim=1,keepdim=True)  
        out=torch.cat((max_out,mean_out),dim=1)  
        out=self.sigmoid(self.conv(out))  
        out=out*channel_out  
        return out  
  
  
if __name__ == "__main__":  
    img = torch.zeros(2, 64, 20, 20)  
    net = CBAM(64)  
    print(net(img).shape)
```


